{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "research = pd.read_csv('OP_DTL_RSRCH_PGYR2017_P01182019.csv')\n",
    "general = pd.read_csv('OP_DTL_GNRL_PGYR2017_P01182019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_research = research.sample(n=10000, random_state=1) # sample 10000 from research\n",
    "sample_general = general.sample(n=10000, random_state=1) # sample 10000 from general "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 Identify Features\n",
    "- Assemble a dataset consisting of features and target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_col = sample_research.columns.values\n",
    "general_col = sample_general.columns.values\n",
    "common_feature = list(set(list(research_col)) & set(list(general_col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "research_1 = sample_research[common_feature]\n",
    "general_1 = sample_general[common_feature]\n",
    "research_1['y'] = [0] * 10000\n",
    "general_1['y'] = [1] * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = research_1.append(general_1)\n",
    "data.index = range(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What features are relevant for the prediction task?\n",
    "- What features should be excluded because they leak the target information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first extracted the common features in research and general datasets. These features are relevent for the prediction. Now let's modify some of those features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify zipcode: to same type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip = data['Recipient_Zip_Code'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in zip.index.values:\n",
    "    if pd.isnull(zip[index]) == False:\n",
    "        if type(zip[index]) == str:\n",
    "            if len(zip[index]) > 5:\n",
    "                zip[index] = zip[index][0:5] \n",
    "        else:\n",
    "            zip[index] = str(int(zip[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Recipient_Zip_Code'] = zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify IDs: All features related to ID should be in type string not float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_id = data['Physician_Profile_ID'].copy()\n",
    "gpo_id = data['Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID'].copy()\n",
    "\n",
    "new_ppid = []\n",
    "new_gpoid = []\n",
    "for index in range(20000):\n",
    "    value = pp_id[index] \n",
    "    value2 = gpo_id[index]\n",
    "    if pd.isnull(value) == False:\n",
    "        new_ppid.append(str(int(value)))\n",
    "    else:\n",
    "        new_ppid.append(value)\n",
    "        \n",
    "    if pd.isnull(value2) == False:\n",
    "        new_gpoid.append(str(int(value2)))\n",
    "    else:\n",
    "        new_gpoid.append(value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Physician_Profile_ID'] = new_ppid\n",
    "data['Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID'] = new_gpoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the number of a feature's nan value is greater than half of length, do not include that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_feature = []\n",
    "for feature in data.columns.values:\n",
    "    temp = data[feature]\n",
    "    if sum(pd.isnull(temp))/len(temp) < 0.5:\n",
    "        left_feature.append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the unique values in that feature is only one or 20000. then delete that feature\n",
    "\n",
    "'Program_Year', length = 1, all 2017 \n",
    "\n",
    "'Delay_in_Publication_Indicator', length = 1, all NO\n",
    "\n",
    "'Payment_Publication_Date', length = 1, all 01/18/2019\n",
    "\n",
    "'Record_ID', length = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_feature_2 = []\n",
    "for col in left_feature:\n",
    "    x = data[col].values\n",
    "    length = len(np.unique(x[pd.notnull(x)]))\n",
    "    if 1 < length & length < 20000:\n",
    "        left_feature_2.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(left_feature_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete features based on descriptions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete 'Covered_Recipient_Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Covered Recipient Physician',\n",
       "       'Covered Recipient Teaching Hospital',\n",
       "       'Non-covered Recipient Entity', 'Non-covered Recipient Individual'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sample_research['Covered_Recipient_Type'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Covered Recipient Physician',\n",
       "       'Covered Recipient Teaching Hospital'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sample_general['Covered_Recipient_Type'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in research, levels are four. But in general, levels are only one. In general dataset, the 'Covered_Recipient_Type' does not have levels 'Non-covered Recipient Entity' and 'Non-covered Recipient Individual'. So this feature leaks the information of target information. We should exclude this feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_feature_2.remove('Covered_Recipient_Type') # exclude Covered_Recipient_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[left_feature_2]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 Preprocessing and Baseline Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's first remove a couple of features.  \n",
    "\n",
    "'Recipient_Primary_Business_Street_Address_Line1' and 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name' has too many levels\n",
    "\n",
    "'Physician_First_Name' and 'physician_Last_Name' seem redundant as Physician_Profile_ID can uniquely define a physician "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 24)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_feature_2.remove('Recipient_Primary_Business_Street_Address_Line1')\n",
    "left_feature_2.remove('Physician_First_Name')\n",
    "left_feature_2.remove('Physician_Last_Name')\n",
    "left_feature_2.remove('Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name')\n",
    "df = data[left_feature_2]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y'].copy()\n",
    "X = df.loc[:, df.columns != 'y'].copy() #23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['Total_Amount_of_Payment_USDollars']\n",
    "categorical = list(set(X_train.columns) - set(continuous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py:739: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "  warnings.warn(message, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "\n",
    "\n",
    "cat_encoder = Pipeline(steps = [('imputer', SimpleImputer(strategy = 'constant', \n",
    "                                                          fill_value = 'N/A')),\n",
    "                               ('encoder', \n",
    "                                OneHotEncoder(categories=[X_train[var].unique() \n",
    "                                                                     for var in categorical],\n",
    "                                                        handle_unknown = 'ignore'))])\n",
    "preprocess = make_column_transformer((continuous, SimpleImputer(strategy='median')), \n",
    "                                     (categorical, cat_encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9560639514071058"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(preprocess, LogisticRegression())\n",
    "val_scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "val_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9572"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use logistic regression, we got score = 0.9572"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlevel = []\n",
    "for i in categorical:\n",
    "    x = X_train[i].values\n",
    "    length = len(np.unique(x[pd.notnull(x)]))\n",
    "    if length > 100:\n",
    "        highlevel.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_category = list(set(categorical) - set(highlevel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace(to_replace={var:np.NaN for var in categorical}, \n",
    "                      value=\"N/A\")\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py:739: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "  warnings.warn(message, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9768003979555997"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "\n",
    "highlevel_encoder = Pipeline(steps = [('encoder', TargetEncoder())])\n",
    "normal_cat_encoder = Pipeline(steps = [('encoder', \n",
    "                                        OneHotEncoder(categories=[X_train[var].unique() \n",
    "                                                                  for var in normal_category],\n",
    "                                                        handle_unknown = 'ignore'))])\n",
    "\n",
    "preprocess = make_column_transformer((continuous, SimpleImputer(strategy='median')), \n",
    "                                     (normal_category, normal_cat_encoder),\n",
    "                                    (highlevel, highlevel_encoder))\n",
    "pipeline = make_pipeline(preprocess, LogisticRegression())\n",
    "\n",
    "\n",
    "val_scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "val_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is improved as the score increased to 0.977"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 Any model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "rf = RandomForestClassifier(warm_start=True, random_state=1)\n",
    "X_test = X_test.replace(to_replace={var:np.NaN for var in categorical}, \n",
    "                          value=\"N/A\")\n",
    "estimator_range = range(1, 150, 5)\n",
    "for n_estimators in estimator_range:\n",
    "    rf.n_estimators = n_estimators\n",
    "    pipeline2 = make_pipeline(preprocess, rf)\n",
    "    pipeline2.fit(X_train, y_train)\n",
    "    train_scores.append(pipeline2.score(X_train, y_train))\n",
    "    test_scores.append(pipeline2.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1834b0dd8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(estimator_range, test_scores, label=\"test scores\")\n",
    "plt.plot(estimator_range, train_scores, label=\"train scores\")\n",
    "plt.plot(list(estimator_range), train_scores,'ro')\n",
    "plt.plot(list(estimator_range), test_scores,'ro')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>test_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.9830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.9854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.9862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0.9844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>0.9852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>0.9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41</td>\n",
       "      <td>0.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>0.9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51</td>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56</td>\n",
       "      <td>0.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>61</td>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>66</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>71</td>\n",
       "      <td>0.9860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>76</td>\n",
       "      <td>0.9852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>81</td>\n",
       "      <td>0.9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>86</td>\n",
       "      <td>0.9854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91</td>\n",
       "      <td>0.9856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>96</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>101</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>106</td>\n",
       "      <td>0.9856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>111</td>\n",
       "      <td>0.9856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>116</td>\n",
       "      <td>0.9854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>121</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>126</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>131</td>\n",
       "      <td>0.9856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>136</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>141</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>146</td>\n",
       "      <td>0.9856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  test_scores\n",
       "0              1       0.9700\n",
       "1              6       0.9830\n",
       "2             11       0.9854\n",
       "3             16       0.9862\n",
       "4             21       0.9844\n",
       "5             26       0.9852\n",
       "6             31       0.9846\n",
       "7             36       0.9848\n",
       "8             41       0.9850\n",
       "9             46       0.9848\n",
       "10            51       0.9846\n",
       "11            56       0.9850\n",
       "12            61       0.9846\n",
       "13            66       0.9858\n",
       "14            71       0.9860\n",
       "15            76       0.9852\n",
       "16            81       0.9848\n",
       "17            86       0.9854\n",
       "18            91       0.9856\n",
       "19            96       0.9858\n",
       "20           101       0.9858\n",
       "21           106       0.9856\n",
       "22           111       0.9856\n",
       "23           116       0.9854\n",
       "24           121       0.9858\n",
       "25           126       0.9858\n",
       "26           131       0.9856\n",
       "27           136       0.9858\n",
       "28           141       0.9858\n",
       "29           146       0.9856"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores\n",
    "score_n = pd.DataFrame({'n_estimators':list(range(1, 150, 5)), \n",
    "                        'test_scores':test_scores})\n",
    "score_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9838\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 41,random_state=0)\n",
    "pipe = make_pipeline(preprocess, rf)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(pipe.score(X_train, y_train))\n",
    "print(pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradientboostingclassifier__learning_rate': 0.2, 'gradientboostingclassifier__max_depth': 10}\n",
      "0.9852\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state = 0)\n",
    "pipe = make_pipeline(preprocess, gbrt)\n",
    "param_grid = {'gradientboostingclassifier__learning_rate': [.2, .1, .05, .02, .01],\n",
    "             'gradientboostingclassifier__max_depth':[5,10,20,30]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5,\n",
    "                   return_train_score=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9852\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(learning_rate = 0.2,\n",
    "                                  random_state = 0, max_depth=10)\n",
    "pipe_gbrt = make_pipeline(preprocess, gbrt)\n",
    "pipe_gbrt.fit(X_train, y_train)\n",
    "print(pipe_gbrt.score(X_train, y_train))\n",
    "print(pipe_gbrt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried Random Forest and Gradient Boosting. Based on the scores, Gradient Boosting is better "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 Feature Selections\n",
    "Identify features that are important for your best model. Which features are most influential, and which features could be removed without decrease in performance? Does removing irrelevant features make your model better?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = pipe_gbrt.named_steps['columntransformer'].named_transformers_[\n",
    "    'pipeline-1'].named_steps['encoder'].get_feature_names()\n",
    "name2 = pipe_gbrt.named_steps['columntransformer'].named_transformers_[\n",
    "    'pipeline-2'].named_steps['encoder'].get_feature_names()\n",
    "name = continuous + list(name1) + list(name2)\n",
    "imp = pd.DataFrame({'feature':name, 'importance':gbrt.feature_importances_})\n",
    "#imp.sort_values('importance',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [0]*imp.shape[0]\n",
    "for i in range(imp.shape[0]):\n",
    "    if i <185:\n",
    "        if imp['feature'][i][0] == 'x':\n",
    "            temp[i] = imp['feature'][i][0:2]\n",
    "        else:\n",
    "            temp[i] = imp['feature'][i]\n",
    "    else: \n",
    "        if imp['feature'][i][0] == 'x':\n",
    "            temp[i] = imp['feature'][i][0:3]\n",
    "        else:\n",
    "            temp[i] = imp['feature'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp['temp'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['x0','x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','x11']\n",
    "table = pd.DataFrame({'temp':x, 'name': normal_category})\n",
    "s1 = pd.merge(imp, table, how='left', on=['temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(s1.shape[0]):\n",
    "  \n",
    "    if s1['feature'][i][0] != 'x':\n",
    "        s1['name'][i] = s1['feature'][i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = s1.drop(columns=['temp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_importance_features = np.unique(s1.loc[s1['importance'] == 0,:]['name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_importance_features = np.unique(s1.loc[s1['importance'] > 0,:]['name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipient_Zip_Code\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1\n",
      "Associated_Drug_or_Biological_NDC_1\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID\n",
      "Change_Type\n",
      "Covered_or_Noncovered_Indicator_1\n",
      "Product_Category_or_Therapeutic_Area_1\n",
      "Recipient_City\n",
      "Total_Amount_of_Payment_USDollars\n",
      "Date_of_Payment\n",
      "Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1\n",
      "Physician_Specialty\n",
      "Physician_Profile_ID\n",
      "Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name\n"
     ]
    }
   ],
   "source": [
    "no_influence_features = list(set(nonzero_importance_features) \n",
    "                             - set(zero_importance_features))\n",
    "\n",
    "for i in no_influence_features:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those features above all have 0 importance values, which could be removed without decrease in performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Physician_Profile_ID</td>\n",
       "      <td>0.920647</td>\n",
       "      <td>Physician_Profile_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "      <td>0.016315</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total_Amount_of_Payment_USDollars</td>\n",
       "      <td>0.015508</td>\n",
       "      <td>Total_Amount_of_Payment_USDollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Name_of_Drug_or_Biological_or_Device_or_Medica...</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>Name_of_Drug_or_Biological_or_Device_or_Medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Recipient_Zip_Code</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>Recipient_Zip_Code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Date_of_Payment</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>Date_of_Payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Submitting_Applicable_Manufacturer_or_Applicab...</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>Submitting_Applicable_Manufacturer_or_Applicab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Product_Category_or_Therapeutic_Area_1</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>Product_Category_or_Therapeutic_Area_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>x3_NC</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Physician_Specialty</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>Physician_Specialty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Recipient_City</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>Recipient_City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>x10_In-kind items and services</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Associated_Drug_or_Biological_NDC_1</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>Associated_Drug_or_Biological_NDC_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>x10_Cash or cash equivalent</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>x3_DE</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>x3_NJ</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>x3_IN</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>x1_Yes</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>x5_Covered</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>Covered_or_Noncovered_Indicator_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>x5_Non-Covered</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>Covered_or_Noncovered_Indicator_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>x3_UT</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>x1_No</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>x4_UNCHANGED</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>Change_Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>x11_MI</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>x4_NEW</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>Change_Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>x5_N/A</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>Covered_or_Noncovered_Indicator_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>x11_TX</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>x0_MN</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>Physician_License_State_code1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>x11_MA</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>x3_IL</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>x6_Austria</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x0_DE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Physician_License_State_code1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>x3_MO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>x3_RI</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>x3_LA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>x3_PR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>x3_NM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>x3_KY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>x3_SC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>x3_DC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>x6_Belgium</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>x6_Norway</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>x11_DC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>x6_Sweden</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>x0_GU</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Physician_License_State_code1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>x0_MS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Physician_License_State_code1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>x0_RI</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Physician_License_State_code1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>x3_AL</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>x11_NH</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>x10_Dividend, profit or other return on invest...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Related_Product_Indicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>x0_ND</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Physician_License_State_code1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>x2_No</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Dispute_Status_for_Publication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>x9_Chiropractor</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Physician_Primary_Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>x2_Yes</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Dispute_Status_for_Publication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>x3_NH</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Applicable_Manufacturer_or_Applicable_GPO_Maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>x7_Canada</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Recipient_Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>x7_Great Britain (Uk)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Recipient_Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>x7_N/A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Recipient_Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>x7_United States</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Recipient_Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>x0_SD</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Physician_License_State_code1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feature  importance  \\\n",
       "199                               Physician_Profile_ID    0.920647   \n",
       "197  Applicable_Manufacturer_or_Applicable_GPO_Maki...    0.016315   \n",
       "0                    Total_Amount_of_Payment_USDollars    0.015508   \n",
       "195  Name_of_Drug_or_Biological_or_Device_or_Medica...    0.007397   \n",
       "192                                 Recipient_Zip_Code    0.006714   \n",
       "198                                    Date_of_Payment    0.004734   \n",
       "201  Submitting_Applicable_Manufacturer_or_Applicab...    0.003583   \n",
       "193             Product_Category_or_Therapeutic_Area_1    0.003122   \n",
       "59                                               x3_NC    0.002674   \n",
       "200                                Physician_Specialty    0.002626   \n",
       "194                                     Recipient_City    0.002463   \n",
       "135                     x10_In-kind items and services    0.001760   \n",
       "196                Associated_Drug_or_Biological_NDC_1    0.001227   \n",
       "136                        x10_Cash or cash equivalent    0.001204   \n",
       "66                                               x3_DE    0.000740   \n",
       "58                                               x3_NJ    0.000629   \n",
       "72                                               x3_IN    0.000612   \n",
       "54                                              x1_Yes    0.000423   \n",
       "100                                         x5_Covered    0.000347   \n",
       "101                                     x5_Non-Covered    0.000346   \n",
       "90                                               x3_UT    0.000337   \n",
       "55                                               x1_No    0.000324   \n",
       "97                                        x4_UNCHANGED    0.000301   \n",
       "149                                             x11_MI    0.000289   \n",
       "98                                              x4_NEW    0.000242   \n",
       "102                                             x5_N/A    0.000238   \n",
       "144                                             x11_TX    0.000182   \n",
       "21                                               x0_MN    0.000181   \n",
       "158                                             x11_MA    0.000181   \n",
       "61                                               x3_IL    0.000167   \n",
       "..                                                 ...         ...   \n",
       "107                                         x6_Austria    0.000000   \n",
       "8                                                x0_DE    0.000000   \n",
       "77                                               x3_MO    0.000000   \n",
       "81                                               x3_RI    0.000000   \n",
       "96                                               x3_LA    0.000000   \n",
       "95                                               x3_PR    0.000000   \n",
       "93                                               x3_NM    0.000000   \n",
       "91                                               x3_KY    0.000000   \n",
       "89                                               x3_SC    0.000000   \n",
       "88                                               x3_DC    0.000000   \n",
       "115                                         x6_Belgium    0.000000   \n",
       "117                                          x6_Norway    0.000000   \n",
       "155                                             x11_DC    0.000000   \n",
       "118                                          x6_Sweden    0.000000   \n",
       "44                                               x0_GU    0.000000   \n",
       "46                                               x0_MS    0.000000   \n",
       "48                                               x0_RI    0.000000   \n",
       "84                                               x3_AL    0.000000   \n",
       "142                                             x11_NH    0.000000   \n",
       "138  x10_Dividend, profit or other return on invest...    0.000000   \n",
       "53                                               x0_ND    0.000000   \n",
       "56                                               x2_No    0.000000   \n",
       "134                                    x9_Chiropractor    0.000000   \n",
       "57                                              x2_Yes    0.000000   \n",
       "73                                               x3_NH    0.000000   \n",
       "122                                          x7_Canada    0.000000   \n",
       "121                              x7_Great Britain (Uk)    0.000000   \n",
       "120                                             x7_N/A    0.000000   \n",
       "119                                   x7_United States    0.000000   \n",
       "49                                               x0_SD    0.000000   \n",
       "\n",
       "                                                  name  \n",
       "199                               Physician_Profile_ID  \n",
       "197  Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "0                    Total_Amount_of_Payment_USDollars  \n",
       "195  Name_of_Drug_or_Biological_or_Device_or_Medica...  \n",
       "192                                 Recipient_Zip_Code  \n",
       "198                                    Date_of_Payment  \n",
       "201  Submitting_Applicable_Manufacturer_or_Applicab...  \n",
       "193             Product_Category_or_Therapeutic_Area_1  \n",
       "59   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "200                                Physician_Specialty  \n",
       "194                                     Recipient_City  \n",
       "135                          Related_Product_Indicator  \n",
       "196                Associated_Drug_or_Biological_NDC_1  \n",
       "136                          Related_Product_Indicator  \n",
       "66   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "58   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "72   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "54                           Related_Product_Indicator  \n",
       "100                  Covered_or_Noncovered_Indicator_1  \n",
       "101                  Covered_or_Noncovered_Indicator_1  \n",
       "90   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "55                           Related_Product_Indicator  \n",
       "97                                         Change_Type  \n",
       "149                          Related_Product_Indicator  \n",
       "98                                         Change_Type  \n",
       "102                  Covered_or_Noncovered_Indicator_1  \n",
       "144                          Related_Product_Indicator  \n",
       "21                       Physician_License_State_code1  \n",
       "158                          Related_Product_Indicator  \n",
       "61   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "..                                                 ...  \n",
       "107  Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "8                        Physician_License_State_code1  \n",
       "77   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "81   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "96   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "95   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "93   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "91   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "89   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "88   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "115  Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "117  Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "155                          Related_Product_Indicator  \n",
       "118  Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "44                       Physician_License_State_code1  \n",
       "46                       Physician_License_State_code1  \n",
       "48                       Physician_License_State_code1  \n",
       "84   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "142                          Related_Product_Indicator  \n",
       "138                          Related_Product_Indicator  \n",
       "53                       Physician_License_State_code1  \n",
       "56                      Dispute_Status_for_Publication  \n",
       "134                             Physician_Primary_Type  \n",
       "57                      Dispute_Status_for_Publication  \n",
       "73   Applicable_Manufacturer_or_Applicable_GPO_Maki...  \n",
       "122                                  Recipient_Country  \n",
       "121                                  Recipient_Country  \n",
       "120                                  Recipient_Country  \n",
       "119                                  Recipient_Country  \n",
       "49                       Physician_License_State_code1  \n",
       "\n",
       "[202 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physician_Profile_ID\n",
      "Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID\n",
      "Total_Amount_of_Payment_USDollars\n",
      "Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1\n",
      "Recipient_Zip_Code\n",
      "Date_of_Payment\n",
      "Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name\n",
      "Product_Category_or_Therapeutic_Area_1\n"
     ]
    }
   ],
   "source": [
    "top8_influential_features = list(s1.sort_values(\n",
    "    'importance',ascending=False)['feature'].values[0:8])\n",
    "for i in top8_influential_features:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those features above are most influential based on their importance score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does removing irrelevant features make your model better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_drop = X_train.copy()\n",
    "X_train_drop = X_train_drop.drop(no_influence_features,axis=1)\n",
    "\n",
    "X_test_drop = X_test.copy()\n",
    "X_test_drop = X_test_drop.drop(no_influence_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = X_train_drop.columns\n",
    "highlevel = []\n",
    "for i in cat:\n",
    "    x = X_train_drop[i].values\n",
    "    length = len(np.unique(x[pd.notnull(x)]))\n",
    "    if length > 100:\n",
    "        highlevel.append(i)\n",
    "## no high level, no continuous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "#preprocess = make_column_transformer((cat, OneHotEncoder()))\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradientboostingclassifier__learning_rate': 0.01, 'gradientboostingclassifier__max_depth': 5}\n",
      "0.9756\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state = 0)\n",
    "pipeline = make_pipeline(preprocessor, gbrt)\n",
    "param_grid = {'gradientboostingclassifier__learning_rate': [.2, .1, .05, .02, .01],\n",
    "             'gradientboostingclassifier__max_depth':[5,10,20,30]}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=5,\n",
    "                   return_train_score=True)\n",
    "grid.fit(X_train_drop, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.score(X_test_drop, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So removing irrelevant features does not make model better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 An explainable model\n",
    "Let's fit a tree using top 8 important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Physician_Profile_ID',\n",
       " 'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_ID',\n",
       " 'Total_Amount_of_Payment_USDollars',\n",
       " 'Name_of_Drug_or_Biological_or_Device_or_Medical_Supply_1',\n",
       " 'Recipient_Zip_Code',\n",
       " 'Date_of_Payment',\n",
       " 'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
       " 'Product_Category_or_Therapeutic_Area_1']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top8_influential_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_infl = X_train.copy()\n",
    "X_train_infl = X_train_infl[top8_influential_features]\n",
    "\n",
    "X_test_infl = X_test.copy()\n",
    "X_test_infl = X_test_infl[top8_influential_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = X_train_infl.columns\n",
    "\n",
    "highlevel = []\n",
    "for i in categorical:\n",
    "    x = X_train_infl[i].values\n",
    "    length = len(np.unique(x[pd.notnull(x)]))\n",
    "    if length > 100:\n",
    "        highlevel.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_category = list(set(categorical) - set(highlevel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py:739: DeprecationWarning: `make_column_transformer` now expects (transformer, columns) as input tuples instead of (columns, transformer). This has been introduced in v0.20.1. `make_column_transformer` will stop accepting the deprecated (columns, transformer) order in v0.22.\n",
      "  warnings.warn(message, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "highlevel_encoder = Pipeline(steps = [('encoder', TargetEncoder())])\n",
    "normal_cat_encoder = Pipeline(steps = [('encoder', OneHotEncoder(categories=[X_train_infl[var].unique() for var in normal_category],\n",
    "                                                        handle_unknown = 'ignore'))])\n",
    "\n",
    "preprocess = make_column_transformer((continuous, SimpleImputer(strategy='median')), \n",
    "                                     (normal_category, normal_cat_encoder),\n",
    "                                    (highlevel, highlevel_encoder))\n",
    "tree = DecisionTreeClassifier(max_leaf_nodes=8)\n",
    "pipeline = make_pipeline(preprocess, tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9836\n",
      "0.9806\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train_infl, y_train)\n",
    "print(pipeline.score(X_train_infl, y_train))\n",
    "print(pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is 0.9806, which is very close to gradient boost's score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
